name: Benchmarks

on:
  schedule:
    # Run nightly benchmarks at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    # Allow manual triggering
    inputs:
      benchmark_type:
        description: 'Type of benchmark to run'
        required: true
        default: 'full'
        type: choice
        options:
        - 'full'
        - 'quick'
        - 'memory'

env:
  CARGO_TERM_COLOR: always
  # Enable terrain tests for benchmark runs
  VF_ENABLE_TERRAIN_TESTS: "1"

jobs:
  # Rust performance benchmarks
  rust-benchmarks:
    name: Rust Performance Benchmarks
    runs-on: ubuntu-latest
    if: github.repository == 'anthropics/forge3d' || github.event_name == 'workflow_dispatch'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
      
      - name: Install benchmark dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libegl1-mesa-dev libgl1-mesa-dev libxcb1-dev
      
      - name: Cache Cargo dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target/
          key: bench-${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
      
      - name: Build release
        run: cargo build --release --workspace
      
      - name: Run Rust benchmarks
        run: |
          cd bench
          # Run the existing benchmark script
          chmod +x ../ci/run_benches.sh
          ../ci/run_benches.sh > benchmark_results.txt 2>&1 || true
          cat benchmark_results.txt
      
      - name: Upload benchmark results
        uses: actions/upload-artifact@v3
        with:
          name: rust-benchmark-results-${{ github.sha }}
          path: |
            bench/benchmark_results.txt
            bench/*.csv

  # Python performance benchmarks
  python-benchmarks:
    name: Python Performance Benchmarks
    runs-on: ubuntu-latest
    if: github.repository == 'anthropics/forge3d' || github.event_name == 'workflow_dispatch'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
      
      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
      
      - name: Install dependencies
        run: |
          pip install maturin[patchelf]==1.4.0 numpy scipy matplotlib
          maturin develop --release
      
      - name: Run Python benchmarks
        run: |
          # Run benchmark examples
          python examples/run_bench.py > python_benchmark_results.txt 2>&1 || true
          cat python_benchmark_results.txt
          
          # Run performance examples if they exist
          if [ -f "examples/terrain_single_tile.py" ]; then
            echo "=== Terrain Performance Test ===" >> python_benchmark_results.txt
            time python examples/terrain_single_tile.py >> python_benchmark_results.txt 2>&1 || true
          fi
          
          if [ -f "examples/triangle_png.py" ]; then
            echo "=== Triangle Rendering Performance ===" >> python_benchmark_results.txt
            time python examples/triangle_png.py >> python_benchmark_results.txt 2>&1 || true
          fi
      
      - name: Memory usage analysis
        run: |
          python -c "
          import forge3d as f3d
          import psutil
          import os
          
          process = psutil.Process(os.getpid())
          
          print('=== Memory Usage Analysis ===')
          print(f'Initial memory: {process.memory_info().rss / 1024 / 1024:.1f} MB')
          
          # Test various operations
          if f3d.has_gpu():
              renderer = f3d.Renderer(512, 512)
              print(f'After Renderer creation: {process.memory_info().rss / 1024 / 1024:.1f} MB')
              
              scene = f3d.Scene(512, 512)
              print(f'After Scene creation: {process.memory_info().rss / 1024 / 1024:.1f} MB')
          
          print('Memory analysis completed')
          " >> python_benchmark_results.txt 2>&1 || true
      
      - name: Upload Python benchmark results
        uses: actions/upload-artifact@v3
        with:
          name: python-benchmark-results-${{ github.sha }}
          path: python_benchmark_results.txt

  # Advanced examples performance testing
  examples-performance:
    name: Advanced Examples Performance
    runs-on: ubuntu-latest
    if: github.event.inputs.benchmark_type == 'full' || github.event_name == 'schedule'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
      
      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
      
      - name: Install dependencies
        run: |
          pip install maturin[patchelf]==1.4.0 numpy scipy matplotlib
          maturin develop --release
      
      - name: Run advanced examples benchmarks
        run: |
          echo "=== Advanced Examples Performance Testing ===" > examples_performance.txt
          
          # Test the 10 advanced examples we created in R13
          examples=(
            "advanced_terrain_shadows_pbr.py"
            "contour_overlay_demo.py" 
            "hdr_tonemap_comparison.py"
            "vector_oit_layering.py"
            "device_capability_probe.py"
            "normal_mapping_terrain.py"
            "ibl_env_lighting.py"
            "multithreaded_command_recording.py"
            "async_compute_prepass.py"
            "large_texture_upload_policies.py"
          )
          
          for example in "\${examples[@]}"; do
            if [ -f "examples/\$example" ]; then
              echo "--- Testing \$example ---" >> examples_performance.txt
              /usr/bin/time -f "Time: %E, Memory: %M KB" python "examples/\$example" >> examples_performance.txt 2>&1 || echo "Failed: \$example" >> examples_performance.txt
              echo "" >> examples_performance.txt
            fi
          done
          
          cat examples_performance.txt
      
      - name: Upload examples performance results
        uses: actions/upload-artifact@v3
        with:
          name: examples-performance-results-${{ github.sha }}
          path: examples_performance.txt

  # Memory stress testing
  memory-stress-test:
    name: Memory Stress Test
    runs-on: ubuntu-latest
    if: github.event.inputs.benchmark_type == 'memory' || github.event.inputs.benchmark_type == 'full'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
      
      - name: Install dependencies
        run: |
          pip install maturin[patchelf]==1.4.0 numpy scipy psutil
          maturin develop --release
      
      - name: Memory stress test
        run: |
          python -c "
          import forge3d as f3d
          import numpy as np
          import psutil
          import gc
          import os
          
          process = psutil.Process(os.getpid())
          print('=== Memory Stress Test ===')
          print(f'Initial memory: {process.memory_info().rss / 1024 / 1024:.1f} MB')
          
          # Test large array handling
          large_arrays = []
          for i in range(5):
              arr = np.random.randint(0, 256, (1024, 1024, 4), dtype=np.uint8)
              large_arrays.append(arr)
              print(f'After array {i+1}: {process.memory_info().rss / 1024 / 1024:.1f} MB')
          
          # Test PNG I/O with large images
          if large_arrays:
              f3d.numpy_to_png('large_test.png', large_arrays[0])
              loaded = f3d.png_to_numpy('large_test.png')
              print(f'After PNG I/O: {process.memory_info().rss / 1024 / 1024:.1f} MB')
          
          # Test GPU memory if available
          if f3d.has_gpu():
              try:
                  renderers = []
                  for i in range(3):
                      renderer = f3d.Renderer(512, 512)
                      renderers.append(renderer)
                      print(f'After renderer {i+1}: {process.memory_info().rss / 1024 / 1024:.1f} MB')
              except Exception as e:
                  print(f'GPU test failed: {e}')
          
          # Cleanup and check memory release
          del large_arrays
          if 'renderers' in locals():
              del renderers
          gc.collect()
          print(f'After cleanup: {process.memory_info().rss / 1024 / 1024:.1f} MB')
          print('Memory stress test completed')
          " > memory_stress_results.txt 2>&1
          
          cat memory_stress_results.txt
      
      - name: Upload memory test results
        uses: actions/upload-artifact@v3
        with:
          name: memory-stress-results-${{ github.sha }}
          path: memory_stress_results.txt

  # Collect and analyze all benchmark results
  analyze-results:
    name: Analyze Benchmark Results
    runs-on: ubuntu-latest
    needs: [rust-benchmarks, python-benchmarks]
    if: always() # Run even if some benchmarks fail
    
    steps:
      - name: Download all benchmark results
        uses: actions/download-artifact@v3
        with:
          path: all-benchmark-results/
      
      - name: Analyze results
        run: |
          echo "=== Benchmark Results Summary ===" > benchmark_summary.txt
          echo "Date: $(date)" >> benchmark_summary.txt
          echo "Commit: ${{ github.sha }}" >> benchmark_summary.txt
          echo "Branch: ${{ github.ref }}" >> benchmark_summary.txt
          echo "" >> benchmark_summary.txt
          
          # Summarize all results
          find all-benchmark-results/ -name "*.txt" -exec echo "=== {} ===" \; -exec cat {} \; >> benchmark_summary.txt
          
          cat benchmark_summary.txt
      
      - name: Upload consolidated results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-summary-${{ github.run_number }}
          path: benchmark_summary.txt
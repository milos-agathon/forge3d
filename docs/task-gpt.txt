# Codex CLI — Auditor → Finisher for Workstream V (forge3d)

ROLE
You are a senior engineer acting as both (A) a rigorous auditor and (B) an implementer/finisher for Workstream V in the forge3d repo.

OBJECTIVE
1) **Audit** if Claude Code fully delivered Workstream **V** from the prior plan (Datashader interop).
2) If anything is missing or partial, **implement and wire it yourself**, in minimal, reviewable commits.

REPO CONTEXT
- Root: .
- Key paths: src/, shaders/, python/forge3d/, python/forge3d/adapters/, examples/, tests/, tests/perf/, tests/goldens/, docs/, .github/workflows/
- Platforms: win_amd64, linux_x86_64, macos_universal2
- APIs: WebGPU/WGSL primary; Vulkan 1.2 compatible design
- Build/tooling: cmake≥3.24, cargo/rustc, PyO3, VMA; docs via Sphinx
- GPU host-visible heap budget: ≤ 512 MiB
- Datashader is an **optional** dependency (gate gracefully).

WORKSTREAM V SCOPE (only)
V1 — Datashader pipeline → RGBA overlay  
V2 — Datashader performance stress & goldens

WHAT “DONE” MEANS (deliverables & measurable ACs)
Deliverables to find or create exactly:
  D1: python/forge3d/adapters/datashader_adapter.py  (class DatashaderAdapter)
  D2: python/forge3d/adapters/__init__.py            (export adapter + probe)
  D3: python/forge3d/__init__.py                     (expose stable namespace forge3d.adapters.datashader_adapter)
  D4: examples/datashader_overlay_demo.py
  D5: examples/output/datashader_overlay_demo.png    (artifact produced by the demo)
  D6: tests/test_datashader_adapter.py               (unit/integration)
  D7: tests/perf/test_datashader_zoom.py             (perf)
  D8: tests/goldens/datashader_Z{0,4,8,12}.png       (+ sidecar JSON with params & hash)
  D9: .github/workflows/datashader-perf.yml          (CI for perf + artifact upload on regression)
  D10: docs/user/datashader_interop.rst              (Sphinx page; in TOC)

Acceptance Criteria to verify or enforce:
  A1 (V1, zero-copy): adapter returns (H,W,4) uint8 RGBA with np.shares_memory(src, out) == True for normal shaded outputs; if a copy is unavoidable, fallback path is explicit and tested.
  A2 (V1, alignment): overlay alignment error ≤ 0.5 px over provided extent/transform (two synthetic extents).
  A3 (V1, example): running `python examples/datashader_overlay_demo.py` writes examples/output/datashader_overlay_demo.png and prints “OK”.
  A4 (V2, fidelity): SSIM ≥ 0.98 vs goldens at Z0, Z4, Z8, Z12 (skimage.metrics.structural_similarity).
  A5 (V2, perf): frame time ≤ 33 ms at Z8 on linux_x86_64 reference runner for a 1e6-point deterministic scene; record the other zooms as a trend table.
  A6 (V2, CI): CI fails on SSIM/latency regression and uploads diff images on failure.
  A7 (All, memory): peak RSS during tests ≤ 512 MiB.
  A8 (Docs): Sphinx builds cleanly; page appears in TOC; includes zero-copy and memory guidance.
  A9 (Optional-dep): core import works without Datashader; tests skip with a clear reason if it’s not installed.

SAFETY & PRACTICES
- Create a feature branch: feat/workstream-v-datashader
- No blind search/replace. Keep commits small and reviewable.
- Don’t modify other workstreams. Avoid binary directories.
- Treat Datashader as optional: guard imports; add a dev extra if needed.

PHASE A — AUDIT (no changes yet)
1) Presence checks: verify all D1–D10 exist at the exact paths above.
2) Content checks:
   - D1 contains class DatashaderAdapter and functions:
       is_datashader_available(), rgba_view_from_agg(), validate_alignment(), to_overlay_texture()
   - D2 exports the adapter and availability probe.
   - D3 exposes forge3d.adapters.datashader_adapter in the public API.
   - D4 demo uses Datashader to produce an RGBA overlay aligned to extent; writes D5 and prints “OK”.
   - D6 asserts zero-copy (np.shares_memory) and alignment error ≤ 0.5 px; skips cleanly if Datashader missing.
   - D7 renders deterministic data at Z{0,4,8,12}, measures frame time, compares SSIM to goldens.
   - D8 goldens exist with sidecar JSON (params, seed, hash).
   - D9 CI workflow runs perf tests, enforces A4/A5, uploads diffs, caches deps.
   - D10 docs page exists; linked in TOC; explains zero-copy, alignment, memory budget.
3) Buildability & docs dry-run (if environment permits):
   - `pip install -e .[dev] datashader`
   - `maturin develop --release`
   - `pytest -k "datashader" -v`
   - `cd docs && make html`
4) Produce an AUDIT REPORT (markdown) summarizing D1–D10 and A1–A9 as ✅/❌ with short evidence. If all ✅, stop and output the report.

PHASE B — IMPLEMENT (only if any ❌ from Phase A)
Implement the minimum changes to turn every ❌ into ✅, in dependency order:

V1 — Datashader pipeline → RGBA overlay
  B1) Add D1 DatashaderAdapter with:
      - Zero-copy RGBA view from Datashader agg/image (prefer memoryview/np.frombuffer).
      - `validate_alignment(extent, transform, width, height)` guarding ≤ 0.5 px tolerance.
      - `to_overlay_texture(rgba, extent)` for renderer upload (document assumptions).
  B2) Wire exports (D2, D3) under stable namespace; soft-import datashader with probe.
  B3) Add demo (D4) producing D5; deterministic seed; CLI print “OK”.
  B4) Write tests (D6):
      - Zero-copy shares_memory true on main path; explicit fallback path also covered.
      - Alignment tests on two synthetic extents.
      - Skip if Datashader unavailable.
V2 — Perf stress & goldens
  B5) Add perf test (D7) with deterministic 1e6 points; zooms Z0/Z4/Z8/Z12; capture frame time and SSIM.
  B6) Generate initial goldens (D8) and sidecar JSON (params, seed, hash).
  B7) Add CI workflow (D9) on linux_x86_64 to run perf tests, enforce A4/A5, upload diff artifacts, and cache deps.
Docs
  B8) Add Sphinx page (D10) with usage, limits, zero-copy notes, memory guidance; add to TOC.

PHASE C — VALIDATE & WRAP
1) Re-run the measurable checks A1–A9 locally (if environment allows) and ensure pass/skip as specified.
2) Update AUDIT REPORT to FINAL REPORT with before/after table.
3) Prepare PR text including:
   - What changed; how to run demo; perf table (zoom→ms); SSIM & memory lines; screenshots of golden vs. current.
4) Output:
   - Branch name, list of new/changed files, FINAL REPORT markdown, and exact local commands:

COMMANDS (reference; run when possible)
- pip install -e .[dev] datashader
- maturin develop --release
- pytest tests/test_datashader_adapter.py -v
- pytest tests/perf/test_datashader_zoom.py -v
- python examples/datashader_overlay_demo.py
- cd docs && make html

REPORTING FORMAT
Return a concise markdown report:
- “Workstream V Audit” table for D1–D10 and A1–A9 (✅/❌ + 1-line evidence)
- If fixes were made: short commit log, perf table, and next steps.

BEGIN NOW.

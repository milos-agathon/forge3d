{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "datashader-intro",
   "metadata": {},
   "source": [
    "# Large-Scale Point Visualization with Datashader\n",
    "\n",
    "This notebook demonstrates large-scale point rendering using the datashader integration adapter.\n",
    "It showcases zero-copy data paths and overlay texture generation for millions of points.\n",
    "\n",
    "**Expected runtime:** < 8 minutes  \n",
    "**Memory usage:** < 400 MiB  \n",
    "**Outputs:** datashader_points.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Add repo root to path for imports\n",
    "if Path('../..').exists():\n",
    "    sys.path.insert(0, str(Path('../..').resolve()))\n",
    "\n",
    "try:\n",
    "    import forge3d as f3d\n",
    "    print(f\"✓ forge3d {f3d.__version__} loaded successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Failed to import forge3d: {e}\")\n",
    "    print(\"Please run: maturin develop --release\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Check datashader availability\n",
    "try:\n",
    "    from forge3d.adapters import (\n",
    "        DatashaderAdapter, \n",
    "        is_datashader_available,\n",
    "        rgba_view_from_agg,\n",
    "        validate_alignment,\n",
    "        shade_to_overlay\n",
    "    )\n",
    "    \n",
    "    datashader_available = is_datashader_available()\n",
    "    print(f\"✓ Datashader integration available: {datashader_available}\")\n",
    "    \n",
    "    if datashader_available:\n",
    "        import datashader as ds\n",
    "        import datashader.transfer_functions as tf\n",
    "        import pandas as pd\n",
    "        print(f\"✓ datashader {ds.__version__} ready\")\n",
    "    else:\n",
    "        print(\"⚠ datashader not available - some features will be skipped\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"⚠ Datashader adapter import failed: {e}\")\n",
    "    datashader_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "device-setup",
   "metadata": {},
   "source": [
    "## Device Setup & Memory Budget\n",
    "\n",
    "Configure GPU device with memory budget awareness for large-scale data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "device-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device information and memory budget\n",
    "try:\n",
    "    device_info = f3d.device_probe()\n",
    "    print(\"🖥️  Device Configuration:\")\n",
    "    print(f\"   Backend: {device_info.get('backend', 'unknown')}\")\n",
    "    print(f\"   Device: {device_info.get('adapter_name', 'unknown')}\")\n",
    "    \n",
    "    # Memory budget for large-scale processing\n",
    "    memory_budget_mb = 400  # Stay well below 512MB limit\n",
    "    print(f\"   Memory budget: {memory_budget_mb} MB (target <512 MB)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠ Device probe failed: {e}\")\n",
    "    memory_budget_mb = 256  # Conservative fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-generation",
   "metadata": {},
   "source": [
    "## Large-Scale Point Data Generation\n",
    "\n",
    "Generate synthetic point cloud data representing a realistic spatial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-points",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate large point dataset\n",
    "np.random.seed(42)  # Deterministic results\n",
    "\n",
    "# Scale based on memory budget (roughly 40 bytes per point with overhead)\n",
    "max_points = int((memory_budget_mb * 1024 * 1024) / 40)\n",
    "num_points = min(1_000_000, max_points)  # Cap at 1M for demo\n",
    "\n",
    "print(f\"📊 Generating point cloud: {num_points:,} points\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Create realistic spatial distribution\n",
    "# Mixture of clustered and uniform distributions\n",
    "cluster_fraction = 0.7\n",
    "num_clusters = int(num_points * cluster_fraction)\n",
    "num_uniform = num_points - num_clusters\n",
    "\n",
    "# Clustered points (cities, hotspots)\n",
    "cluster_centers = np.random.uniform(-100, 100, (5, 2))  # 5 cluster centers\n",
    "cluster_points = []\n",
    "points_per_cluster = num_clusters // len(cluster_centers)\n",
    "\n",
    "for center in cluster_centers:\n",
    "    # Normal distribution around cluster center\n",
    "    cluster_x = np.random.normal(center[0], 15, points_per_cluster)\n",
    "    cluster_y = np.random.normal(center[1], 15, points_per_cluster)\n",
    "    cluster_points.extend(list(zip(cluster_x, cluster_y)))\n",
    "\n",
    "# Uniform background points\n",
    "uniform_x = np.random.uniform(-200, 200, num_uniform)\n",
    "uniform_y = np.random.uniform(-200, 200, num_uniform)\n",
    "uniform_points = list(zip(uniform_x, uniform_y))\n",
    "\n",
    "# Combine all points\n",
    "all_points = cluster_points + uniform_points\n",
    "np.random.shuffle(all_points)  # Mix cluster and uniform points\n",
    "\n",
    "# Convert to arrays\n",
    "points_array = np.array(all_points[:num_points], dtype=np.float32)\n",
    "x_coords = points_array[:, 0]\n",
    "y_coords = points_array[:, 1]\n",
    "\n",
    "# Add value dimension for coloring\n",
    "values = np.random.exponential(scale=2.0, size=num_points).astype(np.float32)\n",
    "values = np.clip(values, 0, 10)  # Reasonable range for visualization\n",
    "\n",
    "generation_time = (time.time() - start_time) * 1000\n",
    "\n",
    "print(f\"✓ Point generation complete: {generation_time:.1f} ms\")\n",
    "print(f\"   X range: [{x_coords.min():.1f}, {x_coords.max():.1f}]\")\n",
    "print(f\"   Y range: [{y_coords.min():.1f}, {y_coords.max():.1f}]\")\n",
    "print(f\"   Value range: [{values.min():.2f}, {values.max():.2f}]\")\n",
    "print(f\"   Memory: {points_array.nbytes / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "datashader-aggregation",
   "metadata": {},
   "source": [
    "## Datashader Aggregation\n",
    "\n",
    "Use datashader to aggregate points into a raster for GPU rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "datashader-agg",
   "metadata": {},
   "outputs": [],
   "source": [
    "if datashader_available:\n",
    "    print(\"🎯 Datashader aggregation...\")\n",
    "    \n",
    "    # Create DataFrame for datashader\n",
    "    df_start = time.time()\n",
    "    df = pd.DataFrame({\n",
    "        'x': x_coords,\n",
    "        'y': y_coords, \n",
    "        'value': values\n",
    "    })\n",
    "    df_time = (time.time() - df_start) * 1000\n",
    "    print(f\"✓ DataFrame created: {df_time:.1f} ms\")\n",
    "    \n",
    "    # Configure canvas for aggregation\n",
    "    canvas_width, canvas_height = 1024, 1024  # High resolution for quality\n",
    "    x_range = (x_coords.min(), x_coords.max())\n",
    "    y_range = (y_coords.min(), y_coords.max())\n",
    "    \n",
    "    canvas = ds.Canvas(\n",
    "        plot_width=canvas_width,\n",
    "        plot_height=canvas_height,\n",
    "        x_range=x_range,\n",
    "        y_range=y_range\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Canvas configured: {canvas_width}×{canvas_height}\")\n",
    "    print(f\"   X range: {x_range}\")\n",
    "    print(f\"   Y range: {y_range}\")\n",
    "    \n",
    "    # Aggregate points by mean value\n",
    "    agg_start = time.time()\n",
    "    agg = canvas.points(df, 'x', 'y', ds.mean('value'))\n",
    "    agg_time = (time.time() - agg_start) * 1000\n",
    "    \n",
    "    print(f\"✓ Aggregation complete: {agg_time:.1f} ms\")\n",
    "    print(f\"   Aggregation shape: {agg.shape}\")\n",
    "    print(f\"   Value range: [{float(agg.min()):.3f}, {float(agg.max()):.3f}]\")\n",
    "    print(f\"   Non-zero pixels: {np.count_nonzero(agg.values):,}\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠ Skipping datashader aggregation - not available\")\n",
    "    # Create fallback synthetic aggregation\n",
    "    canvas_width, canvas_height = 512, 512\n",
    "    agg = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forge3d-integration",
   "metadata": {},
   "source": [
    "## forge3d Integration via Adapter\n",
    "\n",
    "Convert datashader output to forge3d overlay texture using the adapter system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapter-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "if datashader_available and agg is not None:\n",
    "    print(\"🔗 forge3d adapter integration...\")\n",
    "    \n",
    "    # Use adapter for zero-copy conversion\n",
    "    adapter_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Convert aggregation to RGBA overlay using adapter\n",
    "        extent = (float(x_range[0]), float(y_range[0]), \n",
    "                 float(x_range[1]), float(y_range[1]))\n",
    "        \n",
    "        overlay_data = shade_to_overlay(\n",
    "            agg, \n",
    "            extent=extent,\n",
    "            cmap='plasma',  # High contrast for points\n",
    "            how='log'       # Log scaling for better point visibility\n",
    "        )\n",
    "        \n",
    "        adapter_time = (time.time() - adapter_start) * 1000\n",
    "        \n",
    "        print(f\"✓ Adapter conversion: {adapter_time:.1f} ms\")\n",
    "        print(f\"   RGBA shape: {overlay_data['rgba'].shape}\")\n",
    "        print(f\"   Texture format: {overlay_data['format']}\")\n",
    "        print(f\"   Memory sharing: {overlay_data['shares_memory']}\")\n",
    "        print(f\"   Total bytes: {overlay_data['total_bytes'] / 1024 / 1024:.1f} MB\")\n",
    "        \n",
    "        # Validate alignment\n",
    "        alignment_info = validate_alignment(\n",
    "            extent, None, overlay_data['width'], overlay_data['height']\n",
    "        )\n",
    "        print(f\"✓ Coordinate alignment validated: {alignment_info['within_tolerance']}\")\n",
    "        \n",
    "        rgba_overlay = overlay_data['rgba']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Adapter conversion failed: {e}\")\n",
    "        raise\n",
    "        \n",
    "else:\n",
    "    print(\"⚠ Creating fallback visualization...\")\n",
    "    # Create simple fallback visualization\n",
    "    rgba_overlay = np.zeros((512, 512, 4), dtype=np.uint8)\n",
    "    \n",
    "    # Simple scatter plot fallback\n",
    "    for i in range(0, min(10000, len(x_coords)), 100):\n",
    "        px = int((x_coords[i] - x_coords.min()) / (x_coords.max() - x_coords.min()) * 511)\n",
    "        py = int((y_coords[i] - y_coords.min()) / (y_coords.max() - y_coords.min()) * 511)\n",
    "        if 0 <= px < 512 and 0 <= py < 512:\n",
    "            rgba_overlay[py, px] = [255, 100, 200, 255]  # Magenta points\n",
    "    \n",
    "    extent = (float(x_coords.min()), float(y_coords.min()), \n",
    "             float(x_coords.max()), float(y_coords.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rendering",
   "metadata": {},
   "source": [
    "## GPU Rendering with Overlay\n",
    "\n",
    "Render the point visualization using forge3d's GPU pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gpu-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize renderer for overlay rendering\n",
    "render_start = time.time()\n",
    "\n",
    "try:\n",
    "    renderer = f3d.Renderer(1024, 1024, prefer_software=False)\n",
    "    print(f\"✓ Renderer initialized: {renderer.info()}\")\n",
    "    \n",
    "    # Set up basic scene (we'll overlay points on top)\n",
    "    # Create simple background terrain\n",
    "    bg_size = 64\n",
    "    bg_terrain = np.zeros((bg_size, bg_size), dtype=np.float32)\n",
    "    renderer.upload_height_r32f(bg_terrain, spacing=10.0, exaggeration=0.1)\n",
    "    \n",
    "    # Configure camera to match data extent\n",
    "    center_x = (extent[0] + extent[2]) / 2\n",
    "    center_y = (extent[1] + extent[3]) / 2\n",
    "    range_x = extent[2] - extent[0]\n",
    "    range_y = extent[3] - extent[1]\n",
    "    camera_height = max(range_x, range_y) * 0.8\n",
    "    \n",
    "    renderer.set_camera(\n",
    "        eye=(center_x, camera_height, center_y + range_y * 0.3),\n",
    "        target=(center_x, 0.0, center_y),\n",
    "        up=(0.0, 1.0, 0.0)\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Camera positioned for extent: {extent}\")\n",
    "    \n",
    "    # Render base scene\n",
    "    base_render_start = time.time()\n",
    "    base_rgba = renderer.render_rgba()\n",
    "    base_render_time = (time.time() - base_render_start) * 1000\n",
    "    \n",
    "    print(f\"✓ Base scene rendered: {base_render_time:.1f} ms\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Renderer setup failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overlay-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite overlay with base scene\n",
    "print(\"🎨 Compositing overlay...\")\n",
    "\n",
    "composite_start = time.time()\n",
    "\n",
    "try:\n",
    "    # Resize overlay to match render target if needed\n",
    "    target_height, target_width = base_rgba.shape[:2]\n",
    "    overlay_height, overlay_width = rgba_overlay.shape[:2]\n",
    "    \n",
    "    if (overlay_height, overlay_width) != (target_height, target_width):\n",
    "        print(f\"   Resizing overlay: {overlay_width}×{overlay_height} → {target_width}×{target_height}\")\n",
    "        \n",
    "        # Simple nearest-neighbor resize for demo\n",
    "        scale_x = target_width / overlay_width\n",
    "        scale_y = target_height / overlay_height\n",
    "        \n",
    "        resized_overlay = np.zeros((target_height, target_width, 4), dtype=np.uint8)\n",
    "        for y in range(target_height):\n",
    "            for x in range(target_width):\n",
    "                src_x = min(int(x / scale_x), overlay_width - 1)\n",
    "                src_y = min(int(y / scale_y), overlay_height - 1)\n",
    "                resized_overlay[y, x] = rgba_overlay[src_y, src_x]\n",
    "        \n",
    "        rgba_overlay = resized_overlay\n",
    "    \n",
    "    # Alpha blend overlay onto base scene\n",
    "    final_rgba = base_rgba.copy()\n",
    "    \n",
    "    # Simple alpha blending where overlay alpha > 0\n",
    "    overlay_mask = rgba_overlay[:, :, 3] > 0\n",
    "    alpha = rgba_overlay[:, :, 3:4] / 255.0\n",
    "    inv_alpha = 1.0 - alpha\n",
    "    \n",
    "    # Blend RGB channels\n",
    "    for c in range(3):\n",
    "        final_rgba[:, :, c] = (\n",
    "            final_rgba[:, :, c] * inv_alpha[:, :, 0] +\n",
    "            rgba_overlay[:, :, c] * alpha[:, :, 0]\n",
    "        ).astype(np.uint8)\n",
    "    \n",
    "    # Keep original alpha from base\n",
    "    blended_pixels = np.sum(overlay_mask)\n",
    "    \n",
    "    composite_time = (time.time() - composite_start) * 1000\n",
    "    total_render_time = (time.time() - render_start) * 1000\n",
    "    \n",
    "    print(f\"✓ Overlay composited: {composite_time:.1f} ms\")\n",
    "    print(f\"   Blended pixels: {blended_pixels:,}\")\n",
    "    print(f\"   Total render time: {total_render_time:.1f} ms\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Overlay composition failed: {e}\")\n",
    "    final_rgba = base_rgba  # Fallback to base scene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "output-save",
   "metadata": {},
   "source": [
    "## Output Generation & Validation\n",
    "\n",
    "Save final image and validate output quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output\n",
    "output_path = \"datashader_points.png\"\n",
    "save_start = time.time()\n",
    "\n",
    "try:\n",
    "    f3d.numpy_to_png(output_path, final_rgba)\n",
    "    save_time = (time.time() - save_start) * 1000\n",
    "    \n",
    "    # Verify output file\n",
    "    if os.path.exists(output_path):\n",
    "        file_size = os.path.getsize(output_path)\n",
    "        print(f\"✓ Output saved: {output_path} ({file_size / 1024:.1f} KB, {save_time:.1f} ms)\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Output file not created: {output_path}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Save failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance-analysis",
   "metadata": {},
   "source": [
    "## Performance & Memory Analysis\n",
    "\n",
    "Analyze the complete pipeline performance and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive performance summary\n",
    "total_notebook_time = (time.time() - start_time) * 1000\n",
    "\n",
    "print(\"📊 Performance Summary:\")\n",
    "print(f\"   Points processed: {num_points:,}\")\n",
    "print(f\"   Point generation: {generation_time:.1f} ms\")\n",
    "if datashader_available:\n",
    "    print(f\"   DataFrame creation: {df_time:.1f} ms\")\n",
    "    print(f\"   Datashader aggregation: {agg_time:.1f} ms\")\n",
    "    print(f\"   Adapter conversion: {adapter_time:.1f} ms\")\nprint(f\"   GPU base rendering: {base_render_time:.1f} ms\")\nprint(f\"   Overlay composition: {composite_time:.1f} ms\")\nprint(f\"   PNG encoding: {save_time:.1f} ms\")\nprint(f\"   Total notebook time: {total_notebook_time:.1f} ms\")\n\n# Throughput calculations\nif datashader_available:\n    points_per_second = num_points / (total_notebook_time / 1000)\n    print(f\"   Throughput: {points_per_second:,.0f} points/second\")\n\n# Memory analysis\nprint(f\"\\n💾 Memory Analysis:\")\npoint_data_mb = points_array.nbytes / (1024 * 1024)\noutput_mb = final_rgba.nbytes / (1024 * 1024)\noverlay_mb = rgba_overlay.nbytes / (1024 * 1024)\ntotal_memory = point_data_mb + output_mb + overlay_mb\n\nprint(f\"   Point data: {point_data_mb:.1f} MB\")\nprint(f\"   Overlay texture: {overlay_mb:.1f} MB\")\nprint(f\"   Output image: {output_mb:.1f} MB\")\nprint(f\"   Total arrays: {total_memory:.1f} MB\")\nprint(f\"   Budget compliance: {'✓' if total_memory <= memory_budget_mb else '⚠'} (<{memory_budget_mb} MB target)\")\n\n# Quality metrics\nprint(f\"\\n🔍 Output Quality:\")\nprint(f\"   Image dimensions: {final_rgba.shape}\")\nprint(f\"   Data range: [{final_rgba.min()}, {final_rgba.max()}] {final_rgba.dtype}\")\n\n# Content validation\nnon_zero_rgb = np.count_nonzero(final_rgba[:,:,:3])\ntotal_rgb_values = final_rgba.shape[0] * final_rgba.shape[1] * 3\ncontent_ratio = non_zero_rgb / total_rgb_values\n\nprint(f\"   Content ratio: {content_ratio:.2%} non-zero RGB values\")\nprint(f\"   File size: {file_size / 1024:.1f} KB\")\n\n# Runtime compliance\nmax_runtime_ms = 8 * 60 * 1000  # 8 minutes\nruntime_ok = total_notebook_time <= max_runtime_ms\n\nprint(f\"\\n⏱️  Runtime Compliance:\")\nprint(f\"   Actual: {total_notebook_time / 1000:.1f}s\")\nprint(f\"   Target: <{max_runtime_ms / 1000:.0f}s\")\nprint(f\"   Status: {'✓' if runtime_ok else '⚠'} {'Within budget' if runtime_ok else 'Exceeded budget'}\")\n\n# Integration status\nprint(f\"\\n🔗 Integration Status:\")\nif datashader_available:\n    print(f\"   Datashader: ✓ Active\")\n    print(f\"   Zero-copy adapter: ✓ Enabled\")\n    print(f\"   Aggregation method: Mean value with log scaling\")\nelse:\n    print(f\"   Datashader: ⚠ Fallback mode\")\n    \nprint(f\"   GPU acceleration: ✓ Active\")\nprint(f\"   Overlay composition: ✓ Alpha blending\")\n\nprint(f\"\\n✅ Datashader notebook completed!\")\nprint(f\"📁 Output: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metadata-export",
   "metadata": {},
   "source": [
    "## Metadata Export\n",
    "\n",
    "Export performance and configuration metadata for CI validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export metadata for CI validation\n",
    "metadata = {\n",
    "    \"notebook\": \"datashader_points.ipynb\",\n",
    "    \"timestamp\": time.time(),\n",
    "    \"performance\": {\n",
    "        \"points_processed\": int(num_points),\n",
    "        \"total_time_ms\": float(total_notebook_time),\n",
    "        \"datashader_available\": datashader_available,\n",
    "        \"generation_time_ms\": float(generation_time),\n",
    "        \"render_time_ms\": float(base_render_time),\n",
    "        \"save_time_ms\": float(save_time)\n",
    "    },\n",
    "    \"memory\": {\n",
    "        \"budget_mb\": memory_budget_mb,\n",
    "        \"used_mb\": float(total_memory),\n",
    "        \"compliance\": total_memory <= memory_budget_mb\n",
    "    },\n",
    "    \"output\": {\n",
    "        \"file\": output_path,\n",
    "        \"size_kb\": float(file_size / 1024),\n",
    "        \"dimensions\": list(final_rgba.shape),\n",
    "        \"content_ratio\": float(content_ratio)\n",
    "    },\n",
    "    \"validation\": {\n",
    "        \"runtime_ok\": runtime_ok,\n",
    "        \"memory_ok\": total_memory <= memory_budget_mb,\n",
    "        \"output_created\": os.path.exists(output_path),\n",
    "        \"has_content\": content_ratio > 0.01\n",
    "    }\n",
    "}\n",
    "\n",
    "if datashader_available:\n",
    "    metadata[\"performance\"].update({\n",
    "        \"dataframe_time_ms\": float(df_time),\n",
    "        \"aggregation_time_ms\": float(agg_time),\n",
    "        \"adapter_time_ms\": float(adapter_time),\n",
    "        \"points_per_second\": float(points_per_second)\n",
    "    })\n",
    "\n",
    "# Save metadata\n",
    "metadata_path = \"datashader_points_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"📋 Metadata exported: {metadata_path}\")\n",
    "print(f\"   All validations: {'✅ PASS' if all(metadata['validation'].values()) else '❌ FAIL'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}